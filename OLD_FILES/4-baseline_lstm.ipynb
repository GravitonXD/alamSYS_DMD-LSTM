{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of Data\n",
    "\n",
    "# Loading of dataset (PSEI)\n",
    "# We will only use the closing prices, hence we set usecols to index:4\n",
    "data = np.genfromtxt('data/PSEI.csv', delimiter=',', skip_header=1, usecols=4)\n",
    "\n",
    "# Splitting of dataset for training (80%) and testing (20%)\n",
    "# Split data into training and testing\n",
    "len_train = int(len(data) * 0.80)\n",
    "data_train = data[:len_train]\n",
    "data_test = data[len_train:]\n",
    "\n",
    "# Creating a windowed datasets for training, using the following window sizes (5, 10, 15, 20)\n",
    "windowed_sizes = [5, 10, 15, 20]\n",
    "windowed_data_train = [0, 0, 0, 0]\n",
    "\n",
    "idx_counter = 0\n",
    "for window_size in windowed_sizes:\n",
    "    train_data = np.zeros((len(data_train) - window_size, window_size))\n",
    "    for i in range(len(data_train) - window_size):\n",
    "        train_data[i] = data_train[i:i + window_size]\n",
    "    windowed_data_train[idx_counter] = train_data\n",
    "    idx_counter += 1\n",
    "\n",
    "y_data_train = [[], [], [], []]\n",
    "# For y_data_train, in window_size = 5\n",
    "for i in range(len(windowed_data_train[0])):\n",
    "    y_data_train[0].append(windowed_data_train[0][i][1])\n",
    "# For y_data_train, in window_size = 10\n",
    "for i in range(len(windowed_data_train[1])):\n",
    "    y_data_train[1].append(windowed_data_train[1][i][1])\n",
    "# For y_data_train, in window_size = 15\n",
    "for i in range(len(windowed_data_train[2])):\n",
    "    y_data_train[2].append(windowed_data_train[2][i][1])\n",
    "# For y_data_train, in window_size = 20\n",
    "for i in range(len(windowed_data_train[3])):\n",
    "    y_data_train[3].append(windowed_data_train[3][i][1])\n",
    "\n",
    "\n",
    "# Creating a windowed datasets for testing, using the following window sizes (5, 10, 15, 20)\n",
    "windowed_sizes = [5, 10, 15, 20]\n",
    "windowed_data_test = [0, 0, 0, 0]\n",
    "\n",
    "idx_counter = 0\n",
    "for window_size in windowed_sizes:\n",
    "    test_data = np.zeros((len(data_test) - window_size, window_size))\n",
    "    for i in range(len(data_test) - window_size):\n",
    "        test_data[i] = data_test[i:i + window_size]\n",
    "    windowed_data_test[idx_counter] = test_data\n",
    "    idx_counter += 1\n",
    "\n",
    "y_data_test = [[], [], [], []]\n",
    "# For y_data_test, in window_size = 5\n",
    "for i in range(len(windowed_data_test[0])):\n",
    "    y_data_test[0].append(windowed_data_test[0][i][1])\n",
    "# For y_data_test, in window_size = 10\n",
    "for i in range(len(windowed_data_test[1])):\n",
    "    y_data_test[1].append(windowed_data_test[1][i][1])\n",
    "# For y_data_test, in window_size = 15\n",
    "for i in range(len(windowed_data_test[2])):\n",
    "    y_data_test[2].append(windowed_data_test[2][i][1])\n",
    "# For y_data_test, in window_size = 20\n",
    "for i in range(len(windowed_data_test[3])):\n",
    "    y_data_test[3].append(windowed_data_test[3][i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de99ad1dc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Model for window_size = 5\n",
    "window_size = windowed_sizes[0]\n",
    "\n",
    "model_baseline5 =  tf.keras.Sequential()\n",
    "model_baseline5.add(tf.keras.layers.Dense(1, input_shape=(window_size,)))\n",
    "model_baseline5.layers[0].trainable = True\n",
    "\n",
    "# Compile the model_baseline5\n",
    "model_baseline5.compile(optimizer='adam',\n",
    "                 loss='mse',\n",
    "                 metrics=['mae', \n",
    "                          'mape', \n",
    "                          'mean_squared_error'])\n",
    "\n",
    "# Train the model_baseline5\n",
    "y_data_train0 = np.array(y_data_train[0])\n",
    "y_data_test0 = np.array(y_data_test[0])\n",
    "model_baseline5.fit(windowed_data_train[0], \n",
    "             y_data_train0, \n",
    "             epochs=1_000,\n",
    "             verbose=0,\n",
    "             validation_data=(windowed_data_test[0], y_data_test0),\n",
    "             callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de99fe3bb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Model for window_size = 10\n",
    "window_size = windowed_sizes[1]\n",
    "\n",
    "model_baseline10 =  tf.keras.Sequential()\n",
    "model_baseline10.add(tf.keras.layers.Dense(1, input_shape=(window_size,)))\n",
    "model_baseline10.layers[0].trainable = True\n",
    "\n",
    "# Compile the model_baseline10\n",
    "model_baseline10.compile(optimizer='adam',\n",
    "                    loss='mse',\n",
    "                    metrics=['mae',\n",
    "                            'mape',\n",
    "                            'mean_squared_error'])\n",
    "\n",
    "# Train the model_baseline10\n",
    "y_data_train1 = np.array(y_data_train[1])\n",
    "y_data_test1 = np.array(y_data_test[1])\n",
    "model_baseline10.fit(windowed_data_train[1],\n",
    "                y_data_train1,\n",
    "                epochs=1_000,\n",
    "                verbose=0,\n",
    "                validation_data=(windowed_data_test[1], y_data_test1),\n",
    "                callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de9b05b3a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Model for window_size = 15\n",
    "window_size = windowed_sizes[2]\n",
    "\n",
    "model_baseline15 =  tf.keras.Sequential()\n",
    "model_baseline15.add(tf.keras.layers.Dense(1, input_shape=(window_size,)))\n",
    "model_baseline15.layers[0].trainable = True\n",
    "\n",
    "# Compile the model_baseline15\n",
    "model_baseline15.compile(optimizer='adam',\n",
    "                    loss='mse',\n",
    "                    metrics=['mae',\n",
    "                            'mape',\n",
    "                            'mean_squared_error'])\n",
    "\n",
    "# Train the model_baseline15\n",
    "y_data_train2 = np.array(y_data_train[2])\n",
    "y_data_test2 = np.array(y_data_test[2])\n",
    "model_baseline15.fit(windowed_data_train[2],\n",
    "                y_data_train2,\n",
    "                epochs=1_000,\n",
    "                verbose=0,\n",
    "                validation_data=(windowed_data_test[2], y_data_test2),\n",
    "                callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de9d23c0a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Model for window_size = 20\n",
    "window_size = windowed_sizes[3]\n",
    "\n",
    "model_baseline20 =  tf.keras.Sequential()\n",
    "model_baseline20.add(tf.keras.layers.Dense(1, input_shape=(window_size,)))\n",
    "model_baseline20.layers[0].trainable = True\n",
    "\n",
    "# Compile the model_baseline20\n",
    "model_baseline20.compile(optimizer='adam',\n",
    "                    loss='mse',\n",
    "                    metrics=['mae',\n",
    "                            'mape',\n",
    "                            'mean_squared_error'])\n",
    "\n",
    "# Train the model_baseline20\n",
    "y_data_train3 = np.array(y_data_train[3])\n",
    "y_data_test3 = np.array(y_data_test[3])\n",
    "model_baseline20.fit(windowed_data_train[3],\n",
    "                y_data_train3,\n",
    "                epochs=1_000,\n",
    "                verbose=0,\n",
    "                validation_data=(windowed_data_test[3], y_data_test3),\n",
    "                callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRIC RESULTS\n",
      "For window_size = 5: {'loss': <tf.Tensor: shape=(), dtype=float32, numpy=11340.848>, 'mae': <tf.Tensor: shape=(), dtype=float32, numpy=78.48051>, 'mape': <tf.Tensor: shape=(), dtype=float32, numpy=1.1527511>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=11340.848>}\n",
      "\n",
      "For window_size = 10: {'loss': <tf.Tensor: shape=(), dtype=float32, numpy=676.18286>, 'mae': <tf.Tensor: shape=(), dtype=float32, numpy=19.639399>, 'mape': <tf.Tensor: shape=(), dtype=float32, numpy=0.286307>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=676.18286>}\n",
      "\n",
      "For window_size = 15: {'loss': <tf.Tensor: shape=(), dtype=float32, numpy=3537.5012>, 'mae': <tf.Tensor: shape=(), dtype=float32, numpy=44.18517>, 'mape': <tf.Tensor: shape=(), dtype=float32, numpy=0.64862263>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=3537.5012>}\n",
      "\n",
      "For window_size = 20: {'loss': <tf.Tensor: shape=(), dtype=float32, numpy=2164.3389>, 'mae': <tf.Tensor: shape=(), dtype=float32, numpy=36.64485>, 'mape': <tf.Tensor: shape=(), dtype=float32, numpy=0.53514606>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=2164.3389>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"METRIC RESULTS\")\n",
    "print(f\"For window_size = 5: {model_baseline5.get_metrics_result()}\\n\")\n",
    "print(f\"For window_size = 10: {model_baseline10.get_metrics_result()}\\n\")\n",
    "print(f\"For window_size = 15: {model_baseline15.get_metrics_result()}\\n\")\n",
    "print(f\"For window_size = 20: {model_baseline20.get_metrics_result()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Models\n",
    "model_baseline5.save('exported_models/model_baseline5.keras')\n",
    "model_baseline10.save('exported_models/model_baseline10.keras')\n",
    "model_baseline15.save('exported_models/model_baseline15.keras')\n",
    "model_baseline20.save('exported_models/model_baseline20.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c73b41b33398381a63dda394fd0b0cb02413d3de08933cb9c9d1d83148e4d367"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
